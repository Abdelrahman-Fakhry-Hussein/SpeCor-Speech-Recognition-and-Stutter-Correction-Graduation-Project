{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7171864,"sourceType":"datasetVersion","datasetId":4143785},{"sourceId":7687455,"sourceType":"datasetVersion","datasetId":4486033},{"sourceId":7687555,"sourceType":"datasetVersion","datasetId":4486106},{"sourceId":7737409,"sourceType":"datasetVersion","datasetId":4522074},{"sourceId":7737443,"sourceType":"datasetVersion","datasetId":4522099},{"sourceId":7737452,"sourceType":"datasetVersion","datasetId":4522107},{"sourceId":8322639,"sourceType":"datasetVersion","datasetId":4943662},{"sourceId":8768897,"sourceType":"datasetVersion","datasetId":4992848},{"sourceId":8769017,"sourceType":"datasetVersion","datasetId":5269358},{"sourceId":165199443,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tiktoken","metadata":{"_uuid":"97bff47c-d57b-4804-a939-8da5e6dd25bc","_cell_guid":"c2148b4d-8acb-47c0-bbf3-a3bc6345b029","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:05:41.667134Z","iopub.execute_input":"2024-06-24T00:05:41.667682Z","iopub.status.idle":"2024-06-24T00:05:58.834078Z","shell.execute_reply.started":"2024-06-24T00:05:41.667637Z","shell.execute_reply":"2024-06-24T00:05:58.832616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nos.chdir('/kaggle/input/extlibs/.venv/Lib/site-packages')\nimport pydub\nfrom elevenlabs import VoiceSettings\nfrom elevenlabs.client import ElevenLabs\nimport torch\nos.chdir('/kaggle/input')\nfrom transcribe import transcribe\nimport transcribe.transcribe as transcriber\nfrom tokenizer import Tokenizer, get_tokenizer\nfrom model import (Whispersa,TextDecoder,AudioEncoder,ModelDimensions)","metadata":{"_uuid":"7cf5b584-438c-4564-9d7f-791b435d8b20","_cell_guid":"f4abc04a-73db-41f5-afc9-135f1e37708d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:05:58.836722Z","iopub.execute_input":"2024-06-24T00:05:58.83711Z","iopub.status.idle":"2024-06-24T00:06:05.647451Z","shell.execute_reply.started":"2024-06-24T00:05:58.837071Z","shell.execute_reply":"2024-06-24T00:06:05.646252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer =  get_tokenizer()\n# Create an instance of ModelDimensions\ndimensions_instance = ModelDimensions(\n       n_mels=80, n_audio_ctx=1500, n_audio_state=768, n_audio_head=12, n_audio_layer=12, n_vocab=tokenizer.encoding.n_vocab, n_text_ctx=448, n_text_state=768, n_text_head=12, n_text_layer=12\n\n)\ndevice = \"cpu\" #\"cpu\"\nmodel = Whispersa(dimensions_instance).to(device)\nsave_path = \"/kaggle/input/speech-pro1/model3.pt\"  # Replace with your desired path\nmodel.load_state_dict(torch.load(save_path, map_location=torch.device('cpu')))\nmodel.to(device)","metadata":{"_uuid":"69e7cb83-7578-43df-bafa-b8f3e0b9eb9f","_cell_guid":"034f3736-97e0-41a1-b0a1-0356c74403c7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:06:05.648981Z","iopub.execute_input":"2024-06-24T00:06:05.649757Z","iopub.status.idle":"2024-06-24T00:06:18.079724Z","shell.execute_reply.started":"2024-06-24T00:06:05.649714Z","shell.execute_reply":"2024-06-24T00:06:18.078481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = os.listdir(\"/kaggle/input/testdata\")[0]\nresult = transcriber.transcribe(model, fr'/kaggle/input/testdata/{file_name}', language='en', temperature=1.0, word_timestamps=True);","metadata":{"_uuid":"3b757259-5dd4-43ab-ab39-1e72c7c099c4","_cell_guid":"c886bbe7-3297-4b7a-bd58-423b0f1084e7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:06:18.081291Z","iopub.execute_input":"2024-06-24T00:06:18.081615Z","iopub.status.idle":"2024-06-24T00:06:38.757371Z","shell.execute_reply.started":"2024-06-24T00:06:18.081588Z","shell.execute_reply":"2024-06-24T00:06:38.756223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f = open(\"/kaggle/working/transcription.txt\", \"w+\")\nf.write(result['text'])\nf.close()\n\n#open and read the file after the appending:\nf = open(\"/kaggle/working/transcription.txt\", \"r\")\nprint(f.read())","metadata":{"_uuid":"d56d1fef-e317-4e4b-ae28-e963aea5060e","_cell_guid":"33d4ccb1-d26b-4924-a8ec-f6784c8fbfee","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:06:38.760557Z","iopub.execute_input":"2024-06-24T00:06:38.761117Z","iopub.status.idle":"2024-06-24T00:06:38.769923Z","shell.execute_reply.started":"2024-06-24T00:06:38.761086Z","shell.execute_reply":"2024-06-24T00:06:38.768379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_to_speech_file(text: str) -> str:\n    # Calling the text_to_speech conversion API with detailed parameters\n    client = ElevenLabs(api_key=\"sk_00ec341f60b35841ef2468cada45b6e20003f3436beecb00\")\n    response = client.text_to_speech.convert(\n        voice_id=\"pNInz6obpgDQGcFmaJgB\", # Adam pre-made voice\n        optimize_streaming_latency=\"0\",\n        output_format=\"mp3_22050_32\",\n        text=text,\n        model_id=\"eleven_turbo_v2\", # use the turbo model for low latency, for other languages use the `eleven_multilingual_v2`\n        voice_settings=VoiceSettings(\n            stability=0.0,\n            similarity_boost=1.0,\n            style=0.0,\n            use_speaker_boost=True,\n        ),\n    )\n    # Generating a unique file name for the output MP3 file\n    save_file_path = \"/kaggle/working/speech.mp3\"\n    # Writing the audio to a file\n    with open(save_file_path, \"wb\") as f:\n        for chunk in response:\n            if chunk:\n                f.write(chunk)","metadata":{"_uuid":"9e16ce54-a5b2-420b-87e3-752c8ad7a6f2","_cell_guid":"61e3c695-1658-4010-9806-d8f6888bf30c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:06:38.771507Z","iopub.execute_input":"2024-06-24T00:06:38.772007Z","iopub.status.idle":"2024-06-24T00:06:38.782758Z","shell.execute_reply.started":"2024-06-24T00:06:38.771963Z","shell.execute_reply":"2024-06-24T00:06:38.781248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result['text'] = result['text'].replace('stutter', '')\ntext_to_speech_file(result['text'])","metadata":{"_uuid":"3517d619-f033-42e8-a662-2135268e2564","_cell_guid":"9e69c453-89c4-4f88-be09-8dd29ab0e96b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-06-24T00:06:38.784672Z","iopub.execute_input":"2024-06-24T00:06:38.785291Z","iopub.status.idle":"2024-06-24T00:06:39.512292Z","shell.execute_reply.started":"2024-06-24T00:06:38.785244Z","shell.execute_reply":"2024-06-24T00:06:39.510993Z"},"trusted":true},"execution_count":null,"outputs":[]}]}