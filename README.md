**Automatic Speech Recognition (ASR)** technology has significantly advanced, yet it struggles with accurately transcribing speech from individuals with disorders like stuttering and lisping. SpeCor addresses these limitations by incorporating specialized correction mechanisms for these disorders, in turn enhancing ASR accuracy and communication accessibility. SpeCor uses a minimalist preprocessing approach, focusing on robust training with noise and data augmentation to simulate real-world conditions. Feature extraction relies on **Mel-Frequency Cepstral Coefficients (MFCCs)** to capture essential sound characteristics (i.e. phonemes). The **Whisper model**, along with the advanced GPT-2 tokenizer, processes diverse speech patterns. Evaluations using LibriSpeech and LibriStutter datasets show significant improvements for impediment-included speech in Word Error Rate (WER) when training on inclusive datasets **(from 95.5% to 16% WER)**. SpeCorâ€™s architecture, with convolutional layers and transformer blocks, ensures stable and efficient training. This innovation not only enhances the user experience for individuals with speech impediments but also paves the way for further advancements in assistive technologies; this makes voice-based technology more inclusive and reliable for all users. By addressing the unique challenges of speech disorders, SpeCor fosters a more inclusive digital future where everyone can communicate effortlessly using voice-based technologies.
